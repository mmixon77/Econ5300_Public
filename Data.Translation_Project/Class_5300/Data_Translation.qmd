---
title: "Data Exploration Project"
author: "Megan Mixon"
format: html
editor: visual
---

## Quarto

Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see <https://quarto.org>.

## Running Code

When you click the **Render** button a document will be generated that includes both content and the output of embedded code. You can embed code like this:

Read in relevant libraries:

```{r}
library(tidyverse)
library(fixest)
library(rio)
library(vtable)
library(stringr)
library(lubridate)

```

Cleaning the Data:

```{r}
#display all files that contain 'trends_up_to_' in file name
Google_Trends <- list.files(pattern = 'trends_up_to_')

#use import_list() to read in that vector of filenames and bind all results together
Google_Trends <- import_list(Google_Trends, rbind = TRUE, fill = TRUE)
```

```{r}
#aggregating the monthorweek data in Google_Trends
Google_Trends$monthorweek <- str_sub(Google_Trends$monthorweek, 1, 10)

Google_Trends$monthorweek <- ymd(Google_Trends$monthorweek)

Google_Trends$month <- floor_date(Google_Trends$monthorweek, unit = "month")

#aggregating to standardize the index variable by schname and keyword--now a one-unit change in the standardized index can be understood and interpreted as a one-standard-deviation change in the search interest
Google_Trends <- Google_Trends %>%
  group_by(schname, keyword) %>%
  mutate(
    standarized_index = (index - mean(index)) / sd(index)
  )

#reading in the Scorecard data
ScoreCard_data <- Most_Recent_Cohorts_Scorecard_Elements_ <- read_csv("Most+Recent+Cohorts+(Scorecard+Elements).csv")

#reading in the id_name_link data
id_name_link <- read_csv("id_name_link.csv")

#creating variable to count how many times each school name is in id_name_link and filter to get rid of any school names that show up more than once
school_names <- id_name_link %>%
  group_by(schname) %>%
  mutate(n = n()) %>%
  filter(n == 1)

#rename unitid 
ScoreCard_data <- ScoreCard_data %>% rename(unitid = UNITID)  

#merge schname and unitid data together, linking them to ScoreCard_data
merged <- Google_Trends %>%
  inner_join(school_names, by = "schname") %>%
  inner_join(ScoreCard_data, by = "unitid")

#limit the data just to colleges that predominantly grant bachelor's degrees
bach_degree_sch <- merged %>%
  filter(PREDDEG == 3)
```

Analysis:

The research question states: **Among colleges that predominantly grant bachelor's degrees**, did the release of the Scorecard shift student interest to high-earnings colleges relative to low-earnings ones (as proxied by Google searches for keywords associated with those colleges)?

```{r}
#rename variable to show median earnings
bach_degree_sch <- bach_degree_sch %>%
  rename(median_earn = 'md_earn_wne_p10-REPORTED-EARNINGS')

#making median_earn vector into numeric values
bach_degree_sch$'median_earn' <- as.numeric(bach_degree_sch$'median_earn')

#creating a variable to establish how high income versus low income is measured
high_low <- quantile(bach_degree_sch$median_earn, 0.75, na.rm = TRUE)

#creating a dummy variable to determine if median earnings are high or low, based on the threshold
bach_degree_sch <- bach_degree_sch %>%
  mutate(income = ifelse(median_earn > high_low, 0, 1))

#creating a variable for before and after ScoreCard
bach_degree_sch <- bach_degree_sch %>%
  mutate(After_ScoreCard = ymd(month) >= ymd('2015-09-01'))

#creating a variable for cost of college
bach_degree_sch <- bach_degree_sch %>%
  rename(cost = 'NPT4_PUB-AVERAGE-ANNUAL-COST')

#making cost vector into numeric value
bach_degree_sch$'cost' <- as.numeric(bach_degree_sch$'cost')

#noticed a typo in "standarized_index", so I fixed it
bach_degree_sch <- bach_degree_sch %>%
  rename(standardized_index = 'standarized_index')
```

Regression model1:

Due to the research question, the reason I chose to regress standardized_index(Y) on After_ScoreCard(X) and median_earn in model1 is because the standardized index is the variation of search clicks on the colleges; therefore, the standardized index is the outcome that measures the shift in the student's interest on high-earnings colleges relative to low-earnings colleges after the scorecard was released.

The After_ScoreCard is the independent variable in the regression, showing what the effect of X on Y is relative to the median earnings of the colleges.

```{r}
#regress standardized_index on After_Scorecard and median_earn
model1 <- feols(standardized_index ~ After_ScoreCard + median_earn, data = bach_degree_sch)
summary(model1)
etable(model1)
```

Results of model1:

By doing this first regression, it shows us the change in the standard deviations of searches for high earnings schools relative to low earnings schools after the scorecard was released.

Regression model2:

I chose to regress standardized_index(Y) on After_ScoreCard(X) and median_earn(Z), including an interaction term(X\*Z) because I believe by adding an interaction term, it would thoroughly answer the research question, showing whether the student's interest in higher earning colleges relative to lower earning colleges shifted at a particular time.

```{r}
#regress standardized_index on After_ScoreCard and median_earn, along with interaction term
model2 <- feols(standardized_index ~ After_ScoreCard + median_earn + (After_ScoreCard * median_earn), data = bach_degree_sch)
summary(model2)
etable(model2)
```

Results of model2:

Based on the negative coefficients in the second regression, we see that among the colleges that predominantly grant bachelor's degrees, the release of the College Scorecard did not shift student interest to high-earnings colleges relative to low-earnings ones, as proxied by Google searches for keywords associated with those colleges.

Graphs:

By plotting the median earnings to unitid of colleges that predominantly grant bachelor's degrees, we can see a visual comparison of the high-earnings schools to low-earnings schools.

```{r}
#plotting median_earn to unitid to see a visual comparison of high earnings schools to lower earnings schools.
ggplot(data = bach_degree_sch) +
  geom_point(mapping = aes(x = unitid, y = median_earn))
```

By plotting the median earnings to cost of colleges that predominantly grant bachelor's degrees, we can see a visual comparison of the median earnings relative to the cost of attending that college.

```{r}
#plotting median_earn to cost to see a visual comparison of which schools have the highest costs with high earnings schools to lower earnings.
ggplot(data = bach_degree_sch) +
  geom_point(mapping = aes(x = cost, y = median_earn))
```
